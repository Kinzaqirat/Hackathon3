---
id: 1
title: Create Hackathon III Specification
stage: spec
date: 2026-01-20
surface: agent
model: gemini
feature: 002-hackathon-spec
branch: 002-hackathon-spec
user:
command: /sp.specify
labels: [spec, hackathon]
links:
  spec: specs/002-hackathon-spec/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/002-hackathon-spec/spec.md
  - specs/002-hackathon-spec/checklists/requirements.md
tests:
  - 
---

## Prompt

/sp.specify # sp.specify.md # Technical Specifications - Hackathon III ## Repository 1: skills-library ### Repository Structure ``` skills-library/ â”œâ”€â”€ README.md # Repository overview, setup instructions â”œâ”€â”€ .claude/skills/ # Skills directory (Claude + Goose compatible) â”‚ â”œâ”€â”€ agents-md-gen/ â”‚ â”‚ â”œâ”€â”€ SKILL.md # Generate AGENTS.md files â”‚ â”‚ â”œâ”€â”€ REFERENCE.md # Deep documentation â”‚ â”‚ â””â”€â”€ scripts/ â”‚ â”‚ â””â”€â”€ generate_agents_md.py # Repository analyzer â”‚ â”œâ”€â”€ kafka-k8s-setup/ â”‚ â”‚ â”œâ”€â”€ SKILL.md # Deploy Kafka on K8s â”‚ â”‚ â”œâ”€â”€ REFERENCE.md # Kafka configuration docs â”‚ â”‚ â””â”€â”€ scripts/ â”‚ â”‚ â”œâ”€â”€ deploy.sh # Helm install Kafka â”‚ â”‚ â””â”€â”€ verify.py # Pod status checker â”‚ â”œâ”€â”€ postgres-k8s-setup/ â”‚ â”‚ â”œâ”€â”€ SKILL.md # Deploy PostgreSQL on K8s â”‚ â”‚ â”œâ”€â”€ REFERENCE.md # Schema and migration docs â”‚ â”‚ â””â”€â”€ scripts/ â”‚ â”‚ â”œâ”€â”€ deploy.sh # Helm install PostgreSQL â”‚ â”‚ â”œâ”€â”€ migrate.py # Run migrations â”‚ â”‚ â””â”€â”€ verify.py # Connection checker â”‚ â”œâ”€â”€ fastapi-dapr-agent/ â”‚ â”‚ â”œâ”€â”€ SKILL.md # FastAPI + Dapr microservice template â”‚ â”‚ â”œâ”€â”€ REFERENCE.md # Dapr patterns documentation â”‚ â”‚ â””â”€â”€ scripts/ â”‚ â”‚ â”œâ”€â”€ scaffold.py # Generate service boilerplate â”‚ â”‚ â””â”€â”€ dapr_config.py # Dapr component generator â”‚ â”œâ”€â”€ mcp-code-execution/ â”‚ â”‚ â”œâ”€â”€ SKILL.md # MCP Code Execution pattern â”‚ â”‚ â”œâ”€â”€ REFERENCE.md # MCP best practices â”‚ â”‚ â””â”€â”€ scripts/ â”‚ â”‚ â”œâ”€â”€ mcp_client.py # Generic MCP wrapper â”‚ â”‚ â””â”€â”€ example_usage.py # Pattern examples â”‚ â”œâ”€â”€ nextjs-k8s-deploy/ â”‚ â”‚ â”œâ”€â”€ SKILL.md # Next.js Kubernetes deployment â”‚ â”‚ â”œâ”€â”€ REFERENCE.md # Next.js optimization docs â”‚ â”‚ â””â”€â”€ scripts/ â”‚ â”‚ â”œâ”€â”€ build_docker.sh # Dockerfile + build â”‚ â”‚ â”œâ”€â”€ k8s_manifest.py # Generate K8s YAML â”‚ â”‚ â””â”€â”€ deploy.sh # Apply manifests â”‚ â””â”€â”€ docusaurus-deploy/ â”‚ â”œâ”€â”€ SKILL.md # Documentation site deployment â”‚ â”œâ”€â”€ REFERENCE.md # Docusaurus configuration â”‚ â””â”€â”€ scripts/ â”‚ â”œâ”€â”€ init_docusaurus.sh # Scaffold docs site â”‚ â”œâ”€â”€ generate_docs.py # Auto-generate from code â”‚ â””â”€â”€ deploy.sh # Build and deploy â””â”€â”€ docs/ â””â”€â”€ skill-development-guide.md # How to create new Skills ``` ### Skill Specifications #### 1. agents-md-gen **Purpose**: Generate AGENTS.md files for repositories to help AI agents understand project structure. **Inputs**: - Repository path - Project type (Skills library, FastAPI service, Next.js app, etc.) **Outputs**: - `AGENTS.md` file with: - Project overview - Directory structure - File naming conventions - Development guidelines - Key patterns and standards **Script Requirements**: - Analyze repository structure - Detect project type from package files - Generate appropriate conventions - Support custom templates #### 2. kafka-k8s-setup **Purpose**: Deploy Apache Kafka on Kubernetes cluster. **Inputs**: - Namespace (default: kafka) - Replica count (default: 1 for dev) - Zookeeper replica count (default: 1) **Outputs**: - Kafka cluster running in K8s - Topics created: learning.*, code.*, exercise.*, struggle.* - Status verification report **Script Requirements**: - Add Bitnami Helm repository - Install Kafka with configurable parameters - Create namespace if not exists - Verify all pods are Running - Create default topics for LearnFlow #### 3. postgres-k8s-setup **Purpose**: Deploy PostgreSQL database on Kubernetes. **Inputs**: - Namespace (default: database) - Database name - Username/password (from secrets) - Initial schema file path **Outputs**: - PostgreSQL instance running - Database initialized - Migrations applied - Connection string **Script Requirements**: - Install PostgreSQL via Helm - Create secrets for credentials - Apply schema migrations - Verify connectivity - Return connection details #### 4. fastapi-dapr-agent **Purpose**: Scaffold FastAPI microservice with Dapr integration and AI agent capabilities. **Inputs**: - Service name - Agent type (Triage, Concepts, Debug, etc.) - Dapr components (statestore, pubsub, bindings) **Outputs**: - FastAPI project structure - Dapr configuration files - OpenAI Agents SDK integration - Dockerfile and K8s manifests **Script Requirements**: - Generate FastAPI app with routes - Add Dapr SDK integration - Configure OpenAI Agents SDK - Create health check endpoints - Generate Dapr component YAML - Create Kubernetes deployment files #### 5. mcp-code-execution **Purpose**: Demonstrate MCP Code Execution pattern for efficient context usage. **Inputs**: - MCP server type (filesystem, database, API) - Operation to perform **Outputs**: - Executed operation result - Minimal context consumption proof **Script Requirements**: - Generic MCP client wrapper - Example patterns for common operations - Token usage comparison - Best practices documentation #### 6. nextjs-k8s-deploy **Purpose**: Build and deploy Next.js application to Kubernetes. **Inputs**: - Application directory - Namespace - Environment variables - Port configuration **Outputs**: - Docker image built - K8s deployment created - Service exposed - Deployment URL **Script Requirements**: - Generate optimized Dockerfile - Build Docker image - Push to registry (or load to Minikube) - Create K8s Deployment, Service, Ingress - Apply manifests - Verify deployment health #### 7. docusaurus-deploy **Purpose**: Initialize and deploy Docusaurus documentation site. **Inputs**: - Project to document - Output directory - Deployment target (K8s, static hosting) **Outputs**: - Docusaurus site initialized - Documentation generated from code - Site built and deployed **Script Requirements**: - Scaffold Docusaurus project - Auto-generate docs from README, code comments - Configure sidebar navigation - Build static site - Deploy to Kubernetes or hosting platform --- ## Repository 2: learnflow-app ### Application Architecture ``` learnflow-app/ â”œâ”€â”€ AGENTS.md # Generated by agents-md-gen skill â”œâ”€â”€ README.md â”œâ”€â”€ .claude/skills/ # Symlink to skills-library â”œâ”€â”€ frontend/ # Next.js application â”‚ â”œâ”€â”€ src/ â”‚ â”‚ â”œâ”€â”€ app/ # App router â”‚ â”‚ â”œâ”€â”€ components/ â”‚ â”‚ â”‚ â”œâ”€â”€ CodeEditor.tsx # Monaco integration â”‚ â”‚ â”‚ â”œâ”€â”€ ChatInterface.tsx # AI tutor chat â”‚ â”‚ â”‚ â””â”€â”€ Dashboard.tsx # Student/Teacher views â”‚ â”‚ â””â”€â”€ lib/ â”‚ â”‚ â””â”€â”€ api.ts # Backend API client â”‚ â”œâ”€â”€ Dockerfile â”‚ â””â”€â”€ k8s/ â”‚ â”œâ”€â”€ deployment.yaml â”‚ â””â”€â”€ service.yaml â”œâ”€â”€ services/ # FastAPI microservices â”‚ â”œâ”€â”€ triage-agent/ â”‚ â”‚ â”œâ”€â”€ main.py # FastAPI app â”‚ â”‚ â”œâ”€â”€ agent.py # OpenAI Agent â”‚ â”‚ â”œâ”€â”€ dapr/ # Dapr config â”‚ â”‚ â”œâ”€â”€ Dockerfile â”‚ â”‚ â””â”€â”€ k8s/ â”‚ â”œâ”€â”€ concepts-agent/ â”‚ â”œâ”€â”€ code-review-agent/ â”‚ â”œâ”€â”€ debug-agent/ â”‚ â”œâ”€â”€ exercise-agent/ â”‚ â””â”€â”€ progress-agent/ â”œâ”€â”€ infrastructure/ # K8s infrastructure â”‚ â”œâ”€â”€ kafka/ â”‚ â”‚ â””â”€â”€ topics.yaml # Kafka topic definitions â”‚ â”œâ”€â”€ postgres/ â”‚ â”‚ â”œâ”€â”€ schema.sql # Database schema â”‚ â”‚ â””â”€â”€ migrations/ â”‚ â”œâ”€â”€ kong/ â”‚ â”‚ â””â”€â”€ kong.yaml # API Gateway config â”‚ â””â”€â”€ argocd/ â”‚ â””â”€â”€ application.yaml # GitOps config â”œâ”€â”€ mcp-servers/ # MCP context providers â”‚ â”œâ”€â”€ learning-context/ â”‚ â”‚ â””â”€â”€ server.py # Student progress context â”‚ â””â”€â”€ code-execution/ â”‚ â””â”€â”€ server.py # Sandboxed code runner â”œâ”€â”€ docs/ # Docusaurus site â”‚ â”œâ”€â”€ docs/ â”‚ â”œâ”€â”€ blog/ â”‚ â””â”€â”€ docusaurus.config.js â””â”€â”€ scripts/ â””â”€â”€ deploy-all.sh # Orchestrates full deployment ``` ### LearnFlow Specifications #### Frontend: Next.js + Monaco **Features**: - Student Dashboard: Progress visualization, mastery levels - Teacher Dashboard: Class analytics, struggle alerts - Chat Interface: Real-time AI tutor conversations - Code Editor: Monaco editor with syntax highlighting - Code Execution: Submit code, view results inline - Quiz Interface: Multiple choice and coding challenges **Technical Requirements**: - Next.js 14+ with App Router - Monaco Editor integration - Better Auth for authentication - TailwindCSS for styling - Real-time updates via WebSocket or polling - API calls to FastAPI backend via Kong Gateway #### Backend: AI Agent Microservices **Agent Specifications**: | Agent | Endpoint | Input | Output | Kafka Topics | |-------|----------|-------|--------|--------------| | Triage | `/api/triage` | User query | Route decision | `learning.triage` | | Concepts | `/api/concepts` | Topic, level | Explanation + examples | `learning.concepts` | | CodeReview | `/api/review` | Code submission | Quality analysis | `code.review` | | Debug | `/api/debug` | Code + error | Root cause + hints | `code.debug` | | Exercise | `/api/exercise` | Topic, difficulty | Generated challenge | `exercise.generated` | | Progress | `/api/progress` | User ID | Mastery report | `learning.progress` | **Common Service Pattern**: ```python # FastAPI + Dapr + OpenAI Agents SDK from fastapi import FastAPI from dapr.clients import DaprClient from openai import OpenAI app = FastAPI() dapr = DaprClient() client = OpenAI() @app.post("/api/{agent_function}") async def agent_endpoint(request: RequestModel): # 1. Receive request # 2. Call OpenAI Agents SDK # 3. Publish event to Kafka via Dapr # 4. Save state via Dapr statestore # 5. Return response pass ``` #### Database: PostgreSQL Schema **Tables**: - `users`: User accounts (student/teacher) - `modules`: Curriculum modules (1. Basics, 2. Control Flow, etc.) - `topics`: Individual topics within modules - `submissions`: Code submissions history - `quiz_results`: Quiz attempts and scores - `mastery_scores`: Topic mastery tracking - `struggle_alerts`: Triggered when students struggle - `exercises`: Generated coding challenges **Key Relationships**: - Users â†’ Submissions (1:N) - Users â†’ MasteryScores (1:N per topic) - Topics â†’ Exercises (1:N) - Submissions â†’ QuizResults (1:N) #### Messaging: Kafka Topics **Topic Structure**: ``` learning.triage - Query routing decisions learning.concepts - Concept explanations delivered learning.progress - Progress updates code.submitted - Code submission events code.review - Code review results code.debug - Debug assistance provided code.executed - Execution results exercise.generated - New exercises created exercise.completed - Exercise completion events struggle.detected - Struggle alert triggered struggle.resolved - Student overcame struggle ``` **Event Schema Example**: ```json { "event_type": "code.submitted", "timestamp": "2026-01-20T10:30:00Z", "user_id": "student_maya", "data": { "code": "for i in range(5): print(i)", "topic_id": "loops_basic", "session_id": "sess_123" } } ``` #### MCP Servers **learning-context MCP Server**: - Purpose: Provide AI agents with student progress context - Tools: - `get_student_progress(user_id)`: Returns mastery scores - `get_recent_submissions(user_id, limit)`: Recent code attempts - `check_struggle_status(user_id, topic_id)`: Struggle indicators **code-execution MCP Server**: - Purpose: Sandboxed Python code execution - Tools: - `execute_code(code, timeout=5)`: Run code safely - `validate_syntax(code)`: Check for syntax errors - Constraints: 5s timeout, 50MB memory, no network, stdlib only #### API Gateway: Kong **Configuration**: - JWT authentication via Better Auth - Rate limiting: 100 req/min per user - Routes: - `/api/triage/*` â†’ Triage service - `/api/concepts/*` â†’ Concepts service - `/api/review/*` â†’ CodeReview service - `/api/debug/*` â†’ Debug service - `/api/exercise/*` â†’ Exercise service - `/api/progress/*` â†’ Progress service #### CI/CD: Argo CD + GitHub Actions **Workflow**: 1. Developer commits to `main` branch 2. GitHub Actions builds Docker images 3. Images pushed to registry 4. Argo CD detects changes in Git 5. Argo CD syncs K8s manifests 6. New pods deployed with zero downtime **Argo CD Application Config**: ```yaml apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: learnflow spec: source: repoURL: https://github.com/your-org/learnflow-app path: infrastructure/ destination: server: https://kubernetes.default.svc namespace: learnflow syncPolicy: automated: prune: true selfHeal: true ``` --- ## Deployment Specifications ### Local Development (Minikube) - Minikube: 4 CPUs, 8GB RAM - All services run in `learnflow` namespace - Kafka in `kafka` namespace - PostgreSQL in `database` namespace - Access via `minikube service` or port-forward ### Cloud Deployment (Optional) - Target: Azure AKS, Google GKE, or Oracle OKE - Managed Kafka (Confluent Cloud or similar) - Managed PostgreSQL (Azure Database, Cloud SQL, or Neon) - LoadBalancer service for frontend - TLS via cert-manager + Let's Encrypt --- ## Testing & Validation ### Skill Testing Each skill must include validation: - Unit tests for scripts - Integration test: AI agent uses skill successfully - Token efficiency measurement - Cross-agent compatibility test (Claude Code + Goose) ### Application Testing - Frontend: Cypress E2E tests - Backend: pytest for each service - Integration: Full user flow (login â†’ chat â†’ code â†’ quiz) - Performance: Load test with K6 - Security: OWASP ZAP scan ### Success Criteria - âœ… All skills work autonomously - âœ… LearnFlow deployed on Kubernetes - âœ… All 6 AI agents functional - âœ… Kafka events flowing - âœ… PostgreSQL schema applied - âœ… Monaco editor executes code - âœ… Docusaurus site live - âœ… Demo scenario completes end-to-end

## Response snapshot

The feature specification for "Hackathon III" has been created and validated. It includes user stories, functional requirements, key entities, and success criteria based on the provided technical details. The specification is ready for the next phase of planning.

## Outcome

- âœ… Impact: Major. A comprehensive feature specification was created, enabling the project to move to the planning stage.
- ğŸ§ª Tests: N/A
- ğŸ“ Files: 2 created (`specs/002-hackathon-spec/spec.md`, `specs/002-hackathon-spec/checklists/requirements.md`), 1 created (`history/prompts/002-hackathon-spec/1-create-hackathon-iii-specification.spec.prompt.md`)
- ğŸ” Next prompts: `/sp.plan` to begin the technical planning phase for this specification.
- ğŸ§  Reflection: The script for creating feature branches failed, but the process was recovered by creating the necessary files manually. This highlights the need for robust error handling and fallback mechanisms.

## Evaluation notes (flywheel)

- Failure modes observed: `create-new-feature.ps1` script failed with a parameter binding error.
- Graders run and results (PASS/FAIL): N/A
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): Investigate and fix the PowerShell script to handle large string inputs correctly.
